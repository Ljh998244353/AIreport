# 解决模型下载超时问题

## 问题描述

训练脚本在下载 Qwen2.5-0.5B-Instruct 模型时遇到网络超时错误。

## 解决方案

### 方案1：使用专用下载脚本（推荐）

我已经创建了一个专门的下载脚本，会使用镜像站下载模型：

```bash
# 确保设置了镜像站
export HF_ENDPOINT=https://hf-mirror.com

# 运行下载脚本
python download_model.py
```

这个脚本会：
- 自动使用镜像站下载
- 支持断点续传
- 显示下载进度

### 方案2：使用 huggingface-cli

```bash
# 安装 huggingface-cli（如果未安装）
pip install -U huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple

# 设置镜像站
export HF_ENDPOINT=https://hf-mirror.com

# 下载模型
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct \
    --local-dir ./models/cache/Qwen--Qwen2.5-0.5B-Instruct \
    --local-dir-use-symlinks False
```

### 方案3：手动从镜像站下载

1. 访问镜像站：https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct
2. 下载以下文件到 `./models/cache/Qwen/Qwen2.5-0.5B-Instruct/` 目录：
   - `config.json`
   - `model.safetensors` (约988MB)
   - `tokenizer.json`
   - `tokenizer_config.json`
   - `vocab.json`
   - `merges.txt`
   - 其他相关文件

### 方案4：使用 ModelScope（阿里云）

```bash
# 安装 ModelScope
pip install modelscope -i https://pypi.tuna.tsinghua.edu.cn/simple

# 使用 ModelScope 下载
python -c "
from modelscope import snapshot_download
model_dir = snapshot_download('qwen/Qwen2.5-0.5B-Instruct', cache_dir='./models/cache')
print(f'模型已下载到: {model_dir}')
"
```

## 修改后的训练脚本

我已经更新了训练脚本，添加了：
- 自动设置镜像站
- 支持断点续传（`resume_download=True`）

如果模型已部分下载，重新运行训练脚本会自动续传。

## 验证模型是否已下载

```bash
# 检查模型文件
ls -lh ./models/cache/Qwen/Qwen2.5-0.5B-Instruct/

# 应该看到 model.safetensors 文件（约988MB）
```

## 继续训练

模型下载完成后，重新运行训练脚本：

```bash
export HF_ENDPOINT=https://hf-mirror.com
python stage1_finetune/train_lora.py --config config/training_config.yaml
```

## 如果仍然失败

1. **检查网络连接**：确保可以访问 hf-mirror.com
2. **使用代理**：如果有代理，可以设置：
   ```bash
   export http_proxy=http://your-proxy:port
   export https_proxy=http://your-proxy:port
   ```
3. **增加超时时间**：修改 transformers 的默认超时（需要修改库代码，不推荐）
4. **分时段下载**：网络高峰期可能较慢，可以尝试在非高峰期下载


