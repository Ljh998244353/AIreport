# 模型下载方案对比

## 问题分析

从错误日志可以看到，虽然设置了 `HF_ENDPOINT=https://hf-mirror.com`，但实际下载大文件时仍然连接到了 `cas-bridge.xethub.hf.co`（HuggingFace原始服务器），导致超时。

## 推荐方案：使用ModelScope（阿里云）⭐

**优点：**
- ✅ 国内速度最快
- ✅ 不需要设置镜像站
- ✅ 模型格式与HuggingFace完全兼容
- ✅ 可以直接用于训练

**使用方法：**
```bash
# 方法1: 使用脚本（推荐）
bash 快速下载模型.sh

# 方法2: 直接运行Python脚本
python download_from_modelscope.py
```

## 其他方案

### 方案2: 使用huggingface-cli（支持镜像站）

```bash
# 安装工具
pip install -U huggingface_hub -i https://pypi.tuna.tsinghua.edu.cn/simple

# 设置镜像站
export HF_ENDPOINT=https://hf-mirror.com

# 下载模型（支持断点续传）
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct \
    --local-dir ./models/cache/Qwen--Qwen2.5-0.5B-Instruct \
    --local-dir-use-symlinks False
```

### 方案3: 手动下载

1. 访问镜像站：https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct
2. 下载以下文件到 `./models/cache/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/`：
   - `config.json`
   - `model.safetensors` (约988MB)
   - `tokenizer.json`
   - `tokenizer_config.json`
   - `vocab.json`
   - `merges.txt`
   - 其他相关文件

### 方案4: 增加超时时间（不推荐）

如果必须使用HuggingFace镜像站，可以尝试增加超时时间，但效果可能不理想。

## 推荐执行顺序

1. **首选**：使用ModelScope下载（`python download_from_modelscope.py`）
2. **备选**：使用huggingface-cli
3. **最后**：手动下载

## 验证模型是否下载成功

```bash
# 检查模型文件
ls -lh ./models/cache/*/snapshots/*/model*.safetensors

# 应该看到约988MB的model.safetensors文件
```

## 下载完成后

模型下载完成后，可以直接运行训练脚本：

```bash
python stage1_finetune/train_lora.py --config config/training_config.yaml
```

如果使用ModelScope下载，训练脚本会自动识别模型路径。


